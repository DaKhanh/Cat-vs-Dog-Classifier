{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70c57d2-17a3-4b74-b70b-bfba6137d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: numpy in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr1/home/s125mdg24_07/miniconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a6be45-0c48-4de9-8d93-129c696a7df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 1 classes.\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 245ms/step\n",
      "Saved submission.csv!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Load your trained model\n",
    "model = load_model(\"efficientnet_model.keras\")\n",
    "\n",
    "# 2. Define image size (same as during training)\n",
    "IMG_SIZE = (224, 224)  # change if your model used another size\n",
    "\n",
    "# 3. Prepare test data\n",
    "test_dir = \"datasets/datasets\"\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    classes=[\"test\"],           \n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    class_mode=None\n",
    ")\n",
    "\n",
    "\n",
    "## 4. Predict\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Ensure both same length\n",
    "min_len = min(len(predicted_labels), len(test_generator.filenames))\n",
    "predicted_labels = predicted_labels[:min_len]\n",
    "file_names = [os.path.splitext(os.path.basename(f))[0] for f in test_generator.filenames[:min_len]]\n",
    "\n",
    "# 6. Create submission DataFrame\n",
    "submission = pd.DataFrame({\"id\": file_names, \"label\": predicted_labels})\n",
    "submission.to_csv(\"submission_efficient.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74ad252-9b8b-4c9a-940a-dcb4ec6175dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=custom_model.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 1. Load your trained model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcustom_model.keras\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Define image size (same as during training)\u001b[39;00m\n\u001b[32m     11\u001b[39m IMG_SIZE = (\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)  \u001b[38;5;66;03m# change if your model used another size\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/saving/saving_api.py:203\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath,\n\u001b[32m    198\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    199\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    200\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    201\u001b[39m     )\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    210\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=custom_model.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Load your trained model\n",
    "model = load_model(\"custom_model.keras\")\n",
    "\n",
    "# 2. Define image size (same as during training)\n",
    "IMG_SIZE = (224, 224)  # change if your model used another size\n",
    "\n",
    "# 3. Prepare test data\n",
    "test_dir = \"datasets/datasets\"\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    classes=[\"test\"],           \n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    class_mode=None\n",
    ")\n",
    "\n",
    "\n",
    "## 4. Predict\n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "# Ensure both same length\n",
    "min_len = min(len(predicted_labels), len(test_generator.filenames))\n",
    "predicted_labels = predicted_labels[:min_len]\n",
    "file_names = [os.path.splitext(os.path.basename(f))[0] for f in test_generator.filenames[:min_len]]\n",
    "\n",
    "# 6. Create submission DataFrame\n",
    "submission = pd.DataFrame({\"id\": file_names, \"label\": predicted_labels})\n",
    "submission.to_csv(\"submission_efficient.csv\", index=False)\n",
    "\n",
    "print(\"Saved submission.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5eb7da-907a-48e8-810f-b4956a44ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
